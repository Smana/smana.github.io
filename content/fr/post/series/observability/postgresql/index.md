+++
author = "Smaine Kahlouch"
title = "`PostgreSQL`: Des M√©triques √† l'Analyse des Plans de Requ√™tes"
date = "2025-11-15"
summary = "**CloudNativePG** offre un monitoring PostgreSQL relativement complet d√®s l'installation, voyons comment l'am√©liorer gr√¢ce √† l'analyse des requ√™tes SQL et l'**historique des plans d'ex√©cution**."
featured = true
codeMaxLines = 25
usePageBundles = true
toc = true
series = [
  "observability"
]
tags = [
    "observability",
    "data"
]
thumbnail= "thumbnail.png"
+++

Avoir un minimum d'observabilit√© lorsqu'on a du PostgreSQL en production n'est pas optionnel. Que ce soit pour suivre les [Golden Signals](https://blog.ogenki.io/post/series/observability/alerts/#-the-golden-signals), analyser les requ√™tes lentes ou les patterns de connexion. Cela n√©cessite souvent de jongler avec plusieurs outils, configurer divers _exporters_ et extraire manuellement les requ√™tes pour les analyser.

‚ùì Et si nous pouvions obtenir **un niveau de supervision complet pour la production avec un minimum de configuration**?

Dans cet article, nous allons explorer comment aller plus loin en ajoutant √† une supervision d√©j√† bien fournie par CloudNativePG, une capacit√© d'analyse des performances de requ√™tes simple, efficace et facile √† utiliser gr√¢ce √† la puissance des outils que nous avons √† disposition: Vector, VictoriaMetrics et VictoriaLogs.

## üìä Fourni avec CloudNativePG

Lorsque vous d√©ployez un cluster PostgreSQL avec CNPG, une **multitude de m√©triques ainsi que des dashboards Grafana** tr√®s complets sont mis √† disposition. L'op√©rateur expose des m√©triques via un endpoint d√©di√© sur chaque instance PostgreSQL avec les informations suivantes :

* **Op√©rations de Base de Donn√©es** : Taux de transactions, requ√™tes par seconde, statistiques des tuples
* **√âtat de R√©plication** : Lag, √©tat du streaming, m√©triques de synchronisation
* **Utilisation des Ressources** : Connexions, taux de hit du cache, statistiques des buffers
* **Sant√© du Syst√®me** : √âtat des instances, √©v√©nements de failover, √©tats des sauvegardes

{{% notice tip "GitOps et Op√©rateurs Kubernetes" %}}
<table>
  <tr>
        <td>
          <img src="repo_gift.png" style="width:80%;">
        </td>
        <td style="vertical-align:middle; padding-left:10px;" width="70%">

Les exemples de cet article proviennent de configurations disponibles dans le d√©p√¥t <strong><a href="https://github.com/Smana/cloud-native-ref">Cloud Native Ref</a></strong>.</br>
Il exploite plusieurs op√©rateurs, notamment [CloudNativePG](https://cloudnative-pg.io/) pour la gestion PostgreSQL, [VictoriaMetrics](https://victoriametrics.com/) pour la collecte de m√©triques et [VictoriaLogs](https://github.com/VictoriaMetrics/VictoriaLogs) pour la collecte de logs.


Ce projet vise √† <strong>d√©marrer rapidement une plateforme compl√®te</strong> qui suit les meilleures pratiques en termes d'automatisation, de monitoring, de s√©curit√© et plus encore. </br>
Les commentaires et contributions sont les bienvenus üôè
        </td>
  </tr>
</table>
{{% /notice %}}

### Collecter les M√©triques avec VictoriaMetrics

CloudNativePG expose automatiquement des m√©triques sur chaque pod PostgreSQL. Pour activer leur collecte, il suffit de configurer le Helm chart comme suit :

```yaml
# CloudNativePG Helm chart
monitoring:
  podMonitorEnabled: true
```

Cette simple configuration cr√©e un `PodMonitor` (ressource Prometheus Operator) qui est automatiquement converti par l'op√©rateur VictoriaMetrics en ressource native compatible. Les m√©triques de tous les pods PostgreSQL (primary et replicas) sont ainsi collect√©es et disponibles dans VictoriaMetrics.

{{% notice tip "Compatibilit√© Prometheus" %}}
L'op√©rateur VictoriaMetrics convertit automatiquement les ressources Prometheus Operator (`PodMonitor`, `ServiceMonitor`, etc.) en leurs √©quivalents VictoriaMetrics. Cette conversion transparente permet d'utiliser CloudNativePG sans modification, tout en b√©n√©ficiant de VictoriaMetrics comme backend de stockage.
{{% /notice %}}

### M√©triques Essentielles √† Surveiller

CloudNativePG expose des m√©triques qui s'alignent parfaitement avec la m√©thodologie des [Golden Signals](https://blog.ogenki.io/fr/post/series/observability/alerts/#-les-golden-signals) que nous avons abord√©e dans les articles pr√©c√©dents :

**Latence** ‚è≥
```promql
# Dur√©e moyenne des requ√™tes
rate(cnpg_backends_total_seconds_sum[5m]) / rate(cnpg_backends_total_seconds_count[5m])
```

**Trafic** üì∂
```promql
# Transactions par seconde
rate(pg_stat_database_xact_commit[5m]) + rate(pg_stat_database_xact_rollback[5m])
```

**Erreurs** ‚ùå
```promql
# √âchecs de connexion et deadlocks
rate(pg_stat_database_deadlocks[5m])
rate(cnpg_pg_postmaster_start_time_seconds[5m])
```

**Saturation** üìà
```promql
# Utilisation du pool de connexions
cnpg_backends_total / cnpg_pg_settings_max_connections

# Taux de hit du cache (devrait √™tre > 95%)
sum(rate(pg_stat_database_blks_hit[5m])) /
  (sum(rate(pg_stat_database_blks_hit[5m])) + sum(rate(pg_stat_database_blks_read[5m])))
```

### Visualisation avec Grafana

En utilisant l'op√©rateur Grafana que nous avons explor√© dans les [articles pr√©c√©dents](https://blog.ogenki.io/fr/post/series/observability/metrics/#-visualiser-les-m%C3%A9triques-avec-lop%C3%A9rateur-grafana), Nous pouvons d√©ployer les dashboards CNPG de mani√®re d√©clarative :

```yaml
apiVersion: grafana.integreatly.org/v1beta1
kind: GrafanaDashboard
metadata:
  name: databases-cloudnative-pg
spec:
  allowCrossNamespaceImport: true
  folderRef: "databases"
  datasources:
    - inputName: "DS_PROMETHEUS"
      datasourceName: "VictoriaMetrics"
  instanceSelector:
    matchLabels:
      dashboards: "grafana"
  url: "https://grafana.com/api/dashboards/20417/revisions/4/download"
```

Le dashboard fournit des vues compl√®tes de nos clusters PostgreSQL, incluant le lag de r√©plication, les performances des requ√™tes et l'utilisation des ressources.

<center><img src="grafana_cnpg.png" width=1000 alt="CloudNativePG Grafana"></center>


## üîç Comprendre les Performances des Requ√™tes

Les m√©triques nous donnent le "_quoi_" et le "_quand_". En revanche, elles ne nous disent pas toujours le "_pourquoi_". Savoir que les requ√™tes sont lentes est utile ; comprendre **pourquoi** elles sont lentes nous oriente souvent vers des axes d'optimisations.

L'analyse traditionnelle des requ√™tes PostgreSQL n√©cessite d'ex√©cuter manuellement les commandes `EXPLAIN` et `EXPLAIN ANALYZE`. Cette approche a, cependant, ses limites :

* **R√©active** : Vous n'analysez que les requ√™tes que vous soup√ßonnez d'√™tre probl√©matiques
* **Manuelle** : N√©cessite une investigation active par les DBAs
* **Ponctuelle** : Capture le plan d'ex√©cution actuel, pas les tendances historiques
* **Incompl√®te** : Difficile de corr√©ler avec les patterns de charge en production

Id√©alement nous aurions besoin d'une **capture automatique et continue des plans de requ√™tes** qui nous permette de :

1. Identifier automatiquement les requ√™tes lentes
2. Suivre les changements de plans d'ex√©cution dans le temps
3. Corr√©ler les performances des requ√™tes avec les m√©triques syst√®me
4. D√©bugger les probl√®mes de performance sans avoir √† les reproduire manuellement

Certaines solutions de supervision manag√©es offrent cel√†. Mais peut-on s'approcher de cet objectif sur Kubernetes ?

## ‚ú® Historique des Plans de Requ√™tes : Impl√©mentation avec des Outils Open Source

La bonne nouvelle, c'est que nous pouvons construire un syst√®me de suivi des performances de requ√™tes qui rivalise avec les offres commerciales avec un peu de configuration.

### L'Architecture

<center><img src="architecture.png" width=700></center>

Notre solution exploite deux extensions PostgreSQL ainsi qu'un param√®tre de configuration et les int√®gre avec l'√©cosyst√®me VictoriaMetrics :

**Extensions PostgreSQL** :
* **pg_stat_statements** : Agr√®ge les statistiques d'ex√©cution des requ√™tes
* **auto_explain** : Capture automatiquement les plans d'ex√©cution des requ√™tes lentes

**Configuration PostgreSQL** :
* **compute_query_id** : Param√®tre qui g√©n√®re des identifiants uniques pour la corr√©lation des requ√™tes

**Stack d'Observabilit√©** :
* **VictoriaMetrics** : Stocke les m√©triques de requ√™tes depuis `pg_stat_statements`
* **VictoriaLogs** : Stocke les plans d'ex√©cution qui sont g√©n√©r√©s gr√¢ce √† `auto_explain`
* **Vector** : Parse les logs PostgreSQL et extrait les plans d'ex√©cution
* **Grafana** : Visualise les donn√©es de performance et permet l'exploration de l'historique des plans

Le lien essentiel entre tous ces √©l√©ments est la **corr√©lation entre m√©triques et logs utilisant l'identifiant de requ√™te**. Cela nous permet de :
1. Voir qu'une requ√™te est lente (depuis les m√©triques)
2. Cliquer pour voir son historique de plans d'ex√©cution (depuis les logs)
3. Identifier les changements de plan qui ont caus√© des r√©gressions de performance

J'ai appel√© cette fonctionnalit√© "**Performance Insights**". Toute ressemblance avec une solution existante serait fortuite üòÜ.

### Activer Performance Insights

Gr√¢ce aux "[Managed Extensions](https://cloudnative-pg.io/documentation/1.27/postgresql_conf/#managed-extensions)" de CloudNativePG (disponible depuis la v1.23), activer la supervision compl√®te des requ√™tes est hyper simple.

### üèóÔ∏è Platform Engineering : Le Bon Niveau d'Abstraction

L'un des principes cl√©s du _platform engineering_ est de fournir le bon niveau d'abstraction aux d√©veloppeurs/ses. Ils/Elles ne devraient pas avoir besoin de comprendre les internals de PostgreSQL ni de m√©moriser plus de 15 param√®tres de configuration sp√©cifiques √† PostgreSQL.

C'est ici que les **compositions Crossplane** d√©montrent leur int√©r√™t. Dans le projet Cloud Native Ref, nous utilisons Crossplane avec [KCL](https://www.kcl-lang.io/) (Kubernetes Configuration Language) pour cr√©er une abstraction de plus haut niveau appel√©e `SQLInstance`.

**Sans Composition** (Cluster CNPG brut) :
```yaml
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: myapp-postgres
spec:
  instances: 3
  postgresql:
    shared_preload_libraries:
      - pg_stat_statements
      - auto_explain
    parameters:
      pg_stat_statements.max: "10000"
      pg_stat_statements.track: all
      pg_stat_statements.track_utility: "on"
      pg_stat_statements.track_planning: "on"
      pg_stat_statements.save: "on"
      auto_explain.log_format: json
      auto_explain.log_min_duration: "1000"
      auto_explain.log_analyze: "on"
      auto_explain.log_buffers: "on"
      auto_explain.log_timing: "off"
      auto_explain.log_triggers: "on"
      auto_explain.log_verbose: "on"
      auto_explain.log_nested_statements: "on"
      auto_explain.sample_rate: "0.2"
      compute_query_id: on
      track_activity_query_size: 2048
      track_io_timing: "on"
      log_min_duration_statement: 1000
      # ... et plus encore
```

**Avec la Composition** et les param√®tres que nous jugeons pertinents :
```yaml
apiVersion: cloud.ogenki.io/v1alpha1
kind: App
metadata:
  name: myapp
spec:
  sqlInstance:
    enabled: true
    size: small
    storageSize: 20Gi
    instances: 3
    performanceInsights:
      enabled: true
      explain:
        sampleRate: 0.2       # 20% sampling (default: safe for production)
        minDuration: 1000     # Log queries > 1 second (default)
      logStatement: none      # Optional: none (default) / ddl / mod / all
```

La [composition Crossplane](https://github.com/Smana/cloud-native-ref/tree/main/infrastructure/base/crossplane/configuration/kcl/cloudnativepg) **SQLInstance** g√®re toute la complexit√©.

Cette approche par composition offre plusieurs avantages :

1. **Exp√©rience D√©veloppeur/ses** : Les d√©veloppeurs/ses d'applications n'ont pas besoin d'expertise PostgreSQL
2. **Coh√©rence** : La collecte des donn√©es de performances est configur√© uniform√©ment sur toutes les bases de donn√©es
3. **Maintenabilit√©** : L'√©quipe plateforme contr√¥le la configuration de supervision de mani√®re centralis√©e
4. **√âvolutivit√©** : Facile de mettre √† jour les param√®tres pour toutes les instances
5. **D√©couvrabilit√©** : Les d√©veloppeurs/ses peuvent parcourir les options disponibles (`performanceInsights: true`) plut√¥t que m√©moriser les noms de param√®tres

{{% notice tip "Principe de Platform Engineering" %}}
Les meilleures abstractions **cachent la complexit√© sans limiter la puissance**. </br> Les d√©veloppeurs/ses obtiennent des insights de performance avec quelques param√®tres simples, tandis que l'√©quipe plateforme conserve la possibilit√© d'affiner la configuration PostgreSQL sous-jacente pour les cas d'usage avanc√©s.
{{% /notice %}}

### Comprendre la Configuration

D√©taillons ce que fait chaque composant :

**pg_stat_statements** : Cette extension suit les statistiques d'ex√©cution de toutes les instructions SQL ex√©cut√©es par un serveur. Elle enregistre :
* Le temps d'ex√©cution total et le nombre d'appels
* Les lignes trait√©es et retourn√©es
* Les hits et lectures de buffer
* Le temps de planification des requ√™tes

**auto_explain** : Logge automatiquement les plans d'ex√©cution des requ√™tes d√©passant un seuil de dur√©e. Les param√®tres cl√©s sont :
* `log_format: json` : Sortie structur√©e pour le parsing
* `log_min_duration: 1000` : Capturer les requ√™tes prenant plus d'1 seconde
* `log_analyze: on` : Inclure les comptages de lignes r√©els (ex√©cute la requ√™te)
* `sample_rate: 0.2` : √âchantillonnage de 20% des requ√™tes lentes pour r√©duire l'overhead (d√©faut)

**compute_query_id** : La cl√© de corr√©lation qui lie tout ensemble. Cela g√©n√®re un identifiant unique pour chaque requ√™te qui appara√Æt √† la fois dans les m√©triques pg_stat_statements et les logs auto_explain.

{{% notice info "Valeurs par D√©faut" %}}
Par d√©faut, la composition utilise des valeurs s√ªres pour la production :
- `sampleRate: 0.2` ‚Üí 20% d'√©chantillonnage des requ√™tes lentes
- `minDuration: 1000ms` ‚Üí Capture des requ√™tes prenant plus d'1 seconde

Pour le **debugging**, augmentez ces valeurs :
- `sampleRate: 1.0` ‚Üí 100% des requ√™tes lentes
- `minDuration: 0` ‚Üí Toutes les requ√™tes, m√™me les plus rapides
{{% /notice %}}

### Configuration du Pipeline de Logs Vector

Voici ce que Vector fait concr√®tement - **transformation d'un log PostgreSQL auto_explain en √©v√©nement indexable** :

| **Log Brut (CloudNativePG)** | **Apr√®s Parsing Vector** |
|------------------------------|--------------------------|
| <pre lang="json" style="font-size: 0.75em;">{<br>  "timestamp": "2025-01-15T14:32:18.456Z",<br>  "message": "{\\"level\\":\\"info\\",<br>    \\"record\\":{\\"query_id\\":\\"8765432109876543210\\",<br>      \\"database_name\\":\\"production\\",<br>      \\"message\\":\\"duration: 245.678 ms plan:\\\\n{...}\\"<br>    }<br>  }",<br>  "kubernetes": {<br>    "pod_labels": {<br>      "cnpg.io/cluster": "myapp-postgres"<br>    }<br>  }<br>}</pre> | <pre lang="json" style="font-size: 0.75em;">{<br>  "_time": "2025-01-15T14:32:18.456Z",<br>  "cluster_name": "myapp-postgres",<br>  "namespace": "apps",<br>  "database": "production",<br>  "query_id": "8765432109876543210",<br>  "duration_ms": 245.678,<br>  "query_text": "SELECT users.email...",<br>  "plan_json": {<br>    "Node Type": "Hash Join",<br>    "..."<br>  }<br>}</pre> |

#### Pipeline en 3 √âtapes

Le pipeline Vector se compose de **3 transforms** et **2 sinks** ([configuration compl√®te](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/victoria-logs/helmrelease-vlsingle.yaml#L62-L338)) :

**1. Parser les logs JSON CloudNativePG**
```vrl
if .kubernetes.container_name == "postgres" && exists(.kubernetes.pod_labels."cnpg.io/cluster") {
  .log = parse_json(.message)
}
```

**2. Filtrer les plans d'ex√©cution**
```vrl
exists(.log.record.message) && contains(.log.record.message, "plan:")
```

**3. Extraire les m√©tadonn√©es et le plan**
```vrl
.query_id = to_string!(.log.record.query_id)  # Cl√© de corr√©lation
.cluster_name = .kubernetes.pod_labels."cnpg.io/cluster"
.database = .log.record.database_name
# Parser le JSON du plan depuis "duration: X ms plan: {...}"
.plan_json = parse_json(split(.log.record.message, "plan:")[1])
```

Les √©v√©nements pars√©s sont envoy√©s vers deux sinks :
* **Plans r√©ussis** ‚Üí VictoriaLogs avec indexation sur `cluster_name,namespace,database,query_id`
* **√âchecs de parsing** ‚Üí Flux s√©par√© pour debugging

#### La Cl√© : Corr√©lation via query_id

L'√©l√©ment critique est **query_id** qui appara√Æt dans les deux syst√®mes :
* **VictoriaMetrics** : `pg_stat_statements{queryid="8765432109876543210"}` (m√©triques)
* **VictoriaLogs** : `{query_id="8765432109876543210"}` (plans)

Cette corr√©lation permet de sauter instantan√©ment d'une m√©trique de performance √† l'historique des plans d'ex√©cution.

## üî¨ Analyser les Performances des Requ√™tes en Action

Une fois qu'on a identifi√© une requ√™te probl√©matique, nous pouvons voir son historique de plans d'ex√©cution dans VictoriaLogs. En utilisant le `query_id` de `pg_stat_statements`, nous pouvons interroger **VictoriaLogs** :

```logsql
# Trouver tous les plans d'ex√©cution pour une requ√™te sp√©cifique
{cluster_name="myapp-postgres", query_id="1234567890"} | limit 50
```

Cela nous montre :
* Tous les plans d'ex√©cution captur√©s pour cette requ√™te dans le temps
* Les variations de plan (ex : index scans vs. sequential scans)
* Les comptages de lignes r√©els et temps d'ex√©cution
* L'utilisation des buffers et statistiques I/O

### Comprendre la Sortie d'EXPLAIN

Quand auto_explain capture un plan, il fournit des informations d√©taill√©es :

```json
{
  "Query Text": "SELECT * FROM users WHERE email = ?",
  "Query Identifier": 1234567890,
  "Duration": 1567.234,
  "Plan": {
    "Node Type": "Seq Scan",
    "Relation Name": "users",
    "Actual Rows": 1,
    "Actual Loops": 1,
    "Actual Total Time": 1567.123,
    "Shared Hit Blocks": 0,
    "Shared Read Blocks": 54321
  }
}
```

Points cl√©s de ce plan :
* **Sequential Scan** : Scan de toute la table au lieu d'utiliser un index
* **Lectures de blocs √©lev√©es** : 54 321 blocs lus depuis le disque (mauvaise utilisation du cache)
* **Une seule ligne retourn√©e** : Malgr√© le scan de toute la table

Cela sugg√®re imm√©diatement le besoin d'un index sur la colonne `email`.

### üé® Visualiser les Plans d'Ex√©cution avec pev2

Comprendre des plans d'ex√©cution complexes depuis des logs peut √™tre difficile. C'est l√† que **[pev2](https://github.com/dalibo/pev2)** (PostgreSQL Explain Visualizer 2) devient tr√®s utile. C'est un outil web qui transforme les plans d'ex√©cution JSON en diagrammes interactifs et visuels.

```yaml
apiVersion: cloud.ogenki.io/v1alpha1
kind: App
metadata:
  name: xplane-pev2
  namespace: tooling
spec:
  image:
    repository: ghcr.io/smana/pev2
    tag: "v1.17.0"

  resources:
    requests:
      cpu: "10m" # Minimal CPU for static content
      memory: "32Mi" # Small memory footprint
    limits:
      cpu: "300m" # Cap to prevent runaway
      memory: "128Mi" # Limit memory usage

  # Accessible only via Tailscale VPN at: https://pev2.priv.cloud.ogenki.io
  route:
    enabled: true
    hostname: "pev2" # Results in: pev2.priv.cloud.ogenki.io
```

Pour garantir que les donn√©es sensibles de requ√™tes ne quittent jamais le r√©seau, pev2 est auto-h√©berg√© dans le cluster via la composition [App](https://github.com/Smana/cloud-native-ref/tree/main/infrastructure/base/crossplane/configuration/kcl/app). Cela illustre encore une fois le **niveau d'abstraction de la plateforme** : d√©ployer un outil web statique utilise la m√™me API d√©clarative qu'une application compl√®te avec base de donn√©es.

### Analyser avec Grafana

L'int√©gration avec Grafana permet d'identifier rapidement les requ√™tes probl√©matiques et de naviguer jusqu'√† leurs plans d'ex√©cution.

**Dashboard Performance Analysis**

<center><img src="grafana_perf_analysis.png" width=1000 alt="Dashboard Grafana - Analyse des Performances"></center>

Ce dashboard affiche les m√©triques cl√©s depuis `pg_stat_statements` : top requ√™tes par dur√©e totale, latence moyenne, nombre d'appels. Chaque `query_id` est cliquable pour explorer les d√©tails.

**Dashboard Correlation**

<center><img src="grafana_plan_correlation.png" width=1000 alt="Dashboard Grafana - Corr√©lation M√©triques/Logs"></center>

Ce dashboard corr√®le les m√©triques (VictoriaMetrics) avec les plans d'ex√©cution (VictoriaLogs) pour une requ√™te sp√©cifique. Il permet de voir l'√©volution des performances et les changements de plan dans le temps.

### Workflow : De Grafana √† pev2

La vid√©o ci-dessous montre le workflow complet d'investigation : depuis l'identification d'une requ√™te lente dans Grafana jusqu'√† l'analyse visuelle du plan d'ex√©cution avec pev2.

<center>
  <video id="QueryPlan" controls width="1000" autoplay loop muted>
    <source src="workflow.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const video = document.getElementById('QueryPlan');
      video.playbackRate = 1.5;
    });
  </script>
</center>

**√âtapes du workflow** :

1. **Identifier la requ√™te lente** dans le dashboard Grafana (m√©triques `pg_stat_statements`)
2. **Cliquer sur le query_id** pour voir l'historique des plans dans VictoriaLogs
3. **Copier le plan JSON** et ouvrir pev2 (`https://pev2.priv.cloud.ogenki.io`)
4. **Coller le plan** (Ctrl+V) pour visualiser l'ex√©cution

### Exploiter pev2

<center><img src="pev2_query_plan.png" width=900 alt="Visualisation du Plan d'Ex√©cution pev2"></center>

**pev2** transforme les plans JSON en diagrammes interactifs qui r√©v√®lent :

* **Goulots d'√©tranglement** : Les n≈ìuds les plus gros = temps d'ex√©cution le plus √©lev√© (badges orange/jaunes = warnings)
* **Estimations du planificateur** : Divergences entre lignes estim√©es et r√©elles (ex: "under estimated by 443√ó" visible sur le Hash Join principal)
* **Scans s√©quentiels inefficaces** : Indicateurs sur de grandes tables sugg√©rant des index manquants
* **Strat√©gies de jointure** : Hash Join, Nested Loop, Merge Join avec leurs co√ªts respectifs
* **Patterns I/O** : Ratios de blocs lus depuis le disque vs. cache (buffers hits)

L'interface interactive permet de **cliquer sur chaque n≈ìud** pour voir les d√©tails (co√ªt, timing, nombre de lignes, buffers). Les **badges de warning** signalent imm√©diatement les probl√®mes potentiels (estimations erron√©es, scans inefficaces).

Pour les r√©gressions de performance, VictoriaLogs permet de comparer les plans avant/apr√®s en filtrant par p√©riode temporelle (`_time:[...]`), r√©v√©lant les changements de strat√©gie du planificateur PostgreSQL.

## üí≠ Derni√®res remarques

Nous avons construit dans cet article un syst√®me complet d'analyse des performances PostgreSQL qui combine **m√©triques** (`pg_stat_statements`), **plans d'ex√©cution** (`auto_explain`), et **visualisation** (pev2). La cl√© de cette approche r√©side dans la **corr√©lation via query_id** : depuis un dashboard Grafana montrant une requ√™te lente, quelques clics suffisent pour naviguer jusqu'√† son plan d'ex√©cution visualis√© dans pev2, permettant ainsi une analyse puis une optimisation des performances.

Il s'agit, encore une fois, d'une d√©monstration de la **puissance des outils open source disponibles**. CloudNativePG avec l'ajout d'extensions, VictoriaMetrics et VictoriaLogs stockent efficacement m√©triques et logs, Vector parse et structure les donn√©es, et Grafana offre une visualisation unifi√©e. Cette approche native √† Kubernetes est portable, et donne un contr√¥le total.

L'abstraction apport√©e par **Crossplane** amplifie encore cette facilit√©. Gr√¢ce aux compositions `App` et `SQLInstance`, activer Performance Insights se r√©sume √† `performanceInsights.enabled: true` avec quelques param√®tres d'ajustement (`sampleRate`, `minDuration`). Les d√©veloppeurs/ses n'ont pas besoin de comprendre les internals PostgreSQL ni Vector‚Äîla plateforme masque la complexit√©. Cette m√™me API d√©clarative d√©ploie aussi bien une base de donn√©es compl√®te qu'un outil web statique comme pev2, d√©montrant la coh√©rence du niveau d'abstraction.

Le projet [cloud-native-ref](https://github.com/Smana/cloud-native-ref) rassemble toutes ces pi√®ces et montre comment Gateway API, Tailscale, Crossplane/KCL, et l'√©cosyst√®me VictoriaMetrics s'assemblent pour cr√©er une plateforme d'observabilit√© compl√®te.

{{% notice note "Consid√©ration de Performance" %}}
L'activation de Performance Insights implique un overhead mesur√© de **3-4% CPU** et **~200-250MB de m√©moire** avec les valeurs par d√©faut :
- `pg_stat_statements` : ~1% CPU, 50-100MB RAM
- `auto_explain` (sample_rate=0.2, log_timing=off) : ~1% CPU, 50-100MB RAM
- `Vector` parsing : <1% CPU, ~128MB RAM

Les valeurs par d√©faut (`sampleRate: 0.2`, `minDuration: 1000`) sont adapt√©es √† la production. Ajustez selon vos besoins :

* **Production √† forte charge** : `sampleRate: 0.1` (10%) + `minDuration: 3000` (>3s) ‚Äî r√©duire l'overhead √† ~2-3% CPU
* **Debugging/D√©veloppement** : `sampleRate: 1.0` (100%) + `minDuration: 0` + `log_timing: on` ‚Äî overhead ~5-7% CPU pour capture maximale
* **Production standard** : valeurs par d√©faut (`sampleRate: 0.2`, `minDuration: 1000`) ‚Äî excellent √©quilibre √† 3-4% CPU

Les param√®tres `sampleRate`, `log_timing` et `logStatement` permettent d'affiner l'impact sur les performances.
{{% /notice %}}

## üîñ R√©f√©rences

**Documentation CloudNativePG**
- [Documentation Officielle CloudNativePG](https://cloudnative-pg.io/documentation/)
- [Extensions Auto-G√©r√©es](https://cloudnative-pg.io/documentation/current/managed_extensions/)
- [Monitoring et Observabilit√©](https://cloudnative-pg.io/documentation/current/monitoring/)

**Extensions et Fonctionnalit√©s PostgreSQL**
- [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) - Extension de statistiques de requ√™tes
- [auto_explain](https://www.postgresql.org/docs/current/auto-explain.html) - Logging automatique des plans d'ex√©cution
- [compute_query_id](https://www.postgresql.org/docs/14/runtime-config-statistics.html#GUC-COMPUTE-QUERY-ID) - G√©n√©ration d'identifiant de requ√™te
- [Documentation EXPLAIN](https://www.postgresql.org/docs/current/sql-explain.html) - Comprendre les plans de requ√™tes

**√âcosyst√®me VictoriaMetrics**
- [Documentation VictoriaMetrics](https://docs.victoriametrics.com/)
- [VictoriaLogs LogsQL](https://docs.victoriametrics.com/victorialogs/logsql/)
- [Langage VRL de Vector](https://vector.dev/docs/reference/vrl/)

**Visualisation des Plans de Requ√™tes**
- [pev2 (PostgreSQL Explain Visualizer 2)](https://github.com/dalibo/pev2) - Visualisation interactive des plans d'ex√©cution
- [Image Docker pev2](https://hub.docker.com/r/dalibo/pev2) - D√©ploiement auto-h√©berg√©

**Configuration et Impl√©mentation**
- [Configuration Vector VRL](https://github.com/Smana/cloud-native-ref/blob/main/observability/base/victoria-logs/README.md) - Pipeline de parsing des logs PostgreSQL
- [Composition CloudNativePG](https://github.com/Smana/cloud-native-ref/blob/main/infrastructure/base/crossplane/configuration/kcl/cloudnativepg/README.md) - Abstraction SQLInstance avec KCL
- [Architecture de Monitoring PostgreSQL](https://github.com/Smana/cloud-native-ref/blob/main/docs/postgresql-monitoring-architecture.md) - Documentation compl√®te de l'architecture
