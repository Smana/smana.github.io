+++
author = "Smaine Kahlouch"
title = "VictoriaMetrics: Configurer des alertes pertinentes"
date = "2024-10-12"
summary = "Alerter efficacement, VictoriaMetrics operator, slack"
featured = true
codeMaxLines = 21
usePageBundles = true
toc = true
series = [
  "observability"
]
tags = [
    "observability"
]
thumbnail= "thumbnail.png"
+++

{{% notice info "Mieux inspecter nos applications üëÅÔ∏è" %}}
Une fois que notre application est d√©ploy√©e, il est primordial de disposer d'indicateurs permettant d'identifier d'√©ventuels probl√®mes ainsi que suivre les √©volutions de performance. Parmi ces √©l√©ments, les **m√©triques** et les **logs** jouent un r√¥le essentiel en fournissant des informations pr√©cieuses sur le fonctionnement de l'application. En compl√©ment, il est souvent utile de mettre en place un **tracing** d√©taill√© pour suivre pr√©cis√©ment toutes les actions r√©alis√©es par l'application.

Dans cette [s√©rie d'articles](http://localhost:1313/fr/series/observability/), nous allons explorer les diff√©rents aspects li√©s √† la supervision applicative. L'objectif √©tant d'analyser en d√©tail l'√©tat de nos applications, afin d'am√©liorer leur **disponibilit√©** et leurs **performances**, tout en garantissant une exp√©rience utilisateur optimale.
{{% /notice %}}

Lors d'un [pr√©c√©dent article](https://blog.ogenki.io/fr/post/series/observability/metrics/) nous avons vu comment collecter et visualiser des m√©triques. Celles-cis permettent d'analyser le comportement et les performances de nos applications, en revanche il est aussi primordial de configurer des **alertes** afin d'√™tre notifi√© en cas d'anomalies sur notre plateforme.

## üéØ Objectifs

* Comprendre les principales m√©thodologies standards pour un alerting efficace.
* D√©couvrir les langages PromQL et MetricsQL
* Configurer des alertes sur un cas d'usage d'example.
* Router ces alertes sur des canaux slackss

Nous allons voir dans cet article qu'il est tr√®s simple de positionner des seuils au del√† desquels nous serions notifi√©s. Cependant faire en sorte que ces alertes soient pertinentes n'est pas toujours √©vident.

## üîç Qu'est ce qu'une bonne alerte?

<center><img src="chasseurs-chasseur.gif" width=300 alt=""></center>

La gestion des alertes consiste √† configurer des notifications pour informer nos √©quipes des probl√®mes critiques au sein de notre syst√®me. L'objectif est d'identifier et de r√©soudre ces probl√®mes de mani√®re **proactive**, avant qu'ils ne s'aggravent. Des alertes efficaces doivent √™tre :

- Signaler des probl√®mes n√©cessitant une **intervention imm√©diate**.
- Etre d√©clench√©es **au bon moment**: suffisamment t√¥t pour pr√©venir un impact sur les utilisateurs, sans toutefois √™tre trop fr√©quentes au point de provoquer une fatigue li√©e aux alertes.
- Indiquer la **cause racine** ou la zone n√©cessitant une investigation. Il y a notamment un travail de priorisation d'indicateurs pertinents, avec un r√©el impact sur le m√©tier ([SLIs](https://sre.google/sre-book/service-level-objectives/)).

Il est donc important de se focaliser sur un **nombre maitris√©** d'indicateurs √† surveiller. Il existe pour cela des approches qui permettent de mettre en oeuvre une supervision efficace de nos syst√®mes.
Ici nous allons nous pencher sur 2 mod√®les d'alerte reconnus: Les **Core Web Vitals** et les **Golden Signals**.

### üåê Les "Core Web Vitals"

Les Core Web Vitals sont des m√©triques d√©velopp√©es par Google pour √©valuer l'**exp√©rience utilisateur** sur les applications web. Ils mettent en √©vidence des indicateurs li√©s √† la satisfaction des utilisateurs finaux et permettent de garantir que notre application offre de bonnes performances pour les utilisateurs r√©els. Ces m√©triques se concentrent sur trois aspects principaux :

<center><img src="core_web_vitals.png" width=800 alt="Core Web Vitals"></center>

- **Largest Contentful Paint** (LCP), *Temps de chargement de la page* : Le LCP mesure le temps n√©cessaire pour que le plus grand √©l√©ment de contenu visible sur une page web (par exemple, une image, une vid√©o ou un large bloc de texte) soit **enti√®rement rendu** dans la fen√™tre d'affichage. Un bon LCP se situe en dessous de **2,5 secondes**.

- **Interaction to Next Paint** (INP), *R√©activit√©* : L'INP √©value la r√©activit√© d'une page web en mesurant la **latence de toutes les interactions** utilisateur, telles que les clics, les taps et les entr√©es clavier, etc... Elle refl√®te le temps n√©cessaire pour qu'une page r√©agisse visuellement √† une interaction, c'est-√†-dire le d√©lai avant que le navigateur affiche le prochain rendu apr√®s une action de l'utilisateur. un bon INP doit √™tre inf√©rieur √† **200 millisecondes**

- **Cumulative Layout Shift** (CLS), *Stabilit√© visuelle* : Le CLS √©value la **stabilit√© visuelle** en quantifiant les d√©calages de mise en page inattendus sur une page, lorsque des √©l√©ments se d√©placent pendant le chargement ou l'interaction. Un bon score CLS est inf√©rieur ou √©gal √† **0,1**.

{{% notice info "D'autres indicateurs" %}}
Il existe √©galement d'autres indicateurs, que l'on ne d√©taillera pas ici, mais qui m√©ritent d'√™tre √©tudi√©s : **[FCP](https://web.dev/articles/fcp)** (First Contentful Paint), **[TTFB](https://web.dev/articles/ttfb)** (Time To First Byte), etc...
{{% /notice %}}

La performance d'un site web est consid√©r√©e satisfaisante si elle atteint les seuils d√©crits ci-dessus au **75·µâ percentile**, favorisant ainsi une bonne exp√©rience utilisateur et, par cons√©quent, une meilleure r√©tention et un meilleur r√©f√©rencement ([SEO](https://en.wikipedia.org/wiki/Search_engine_optimization)).

Cependant, l'ajout d'alertes sp√©cifiques sur ces m√©triques doit √™tre m√ªrement r√©fl√©chi. Contrairement aux indicateurs op√©rationnels classiques, tels que la disponibilit√© ou le taux d'erreurs, qui refl√®tent directement la stabilit√© du syst√®me, Les *Web Vitals* d√©pendent de **nombreux facteurs externes**, comme les conditions r√©seau des utilisateurs ou leurs appareils, rendant les seuils plus complexes √† surveiller efficacement.

Pour √©viter une surcharge d'alertes inutiles, ces alertes doivent uniquemement cibler des **d√©gradations significatives**. Par exemple, une augmentation soudaine du **CLS** (stabilit√© visuelle) ou une d√©t√©rioration continue du **LCP** (temps de chargement) sur plusieurs jours peuvent indiquer des probl√®mes importants n√©cessitant une intervention.

Enfin, ces alertes n√©cessitent des outils adapt√©s, comme le *RUM (Real User Monitoring)* pour les donn√©es r√©elles ou le *Synthetic Monitoring* pour des tests simul√©s, qui requi√®rent une solution sp√©cifique non abord√©e dans cet article.

### ‚ú® Les "Golden Signals"

Les Golden Signals (ou signaux d'or) sont un ensemble de **quatre indicateurs cl√©s**, largement utilis√©s dans le domaine de la supervision des syst√®mes et des applications, notamment avec des outils comme Prometheus. Ces signaux permettent de surveiller la sant√© et la performance des applications de mani√®re efficace. Ils sont particuli√®rement appropri√©s dans le contexte d'une architecture distribu√©e:

* **La Latence** ‚è≥: Elle inclut √† la fois le temps des requ√™tes r√©ussies et le temps des requ√™tes √©chou√©es. La latence est cruciale car une augmentation du temps de r√©ponse peut indiquer des probl√®mes de performance.

* **Le Trafic** üì∂: Il peut √™tre mesur√©e en termes de nombre de requ√™tes par seconde, de d√©bit de donn√©es, ou d'autres m√©triques qui expriment la charge du syst√®me.

* **Les erreurs** ‚ùå: Il s'agit du taux d'√©chec des requ√™tes ou des transactions. Cela peut inclure des erreurs d'application, des erreurs d'infrastructure ou toute situation o√π une requ√™te ne s'est pas termin√©e correctement (par exemple, des r√©ponses HTTP 5xx ou des requ√™tes rejet√©es).

* **La saturation** üìà: C'est une mesure de l'utilisation des ressources du syst√®me, comme le CPU, la m√©moire ou la bande passante r√©seau. La saturation indique √† quel point le syst√®me est proche de ses limites. Un syst√®me satur√© peut entra√Æner des ralentissements ou des pannes.

Ces Golden Signals sont essentiels car ils permettent de **concentrer la surveillance sur les aspects critiques** qui peuvent rapidement affecter l'exp√©rience utilisateur ou la performance globale du syst√®me. Avec Prometheus, ces signaux sont souvent surveill√©s via des m√©triques sp√©cifiques pour d√©clencher des alertes lorsque certains seuils sont d√©pass√©s.



Alerting is not one-size-fits-all. By understanding and implementing the RED methodology, Golden Signals, and Web Vitals, you can ensure that your alerts are meaningful, actionable, and aligned with both system health and user satisfaction. Start by identifying your key metrics, set clear thresholds, and continually refine your approach for better results.

RED and Golden Signals have significant overlap, making both powerful frameworks for system monitoring. While RED excels in simplicity for microservices, Golden Signals' broader scope is better suited for large-scale distributed systems. Meanwhile, Web Vitals ensures a focus on user satisfaction. By integrating these patterns, you‚Äôll build a balanced and effective alerting system that keeps your applications performant and your users happy.



* Grafana oncall
* AI runbooks


https://docs.victoriametrics.com/vmalert/
VMAlert, ruler evaluation des alertes en fonction de seuils.
Alertmanage notifications

## üíª Exprimer des requ√™tes avec PromQL/MetricsQL

Prometheus, promQL basics. MetricsQL
recording rules vs ... rules


## üõ†Ô∏è Configure des alertes avec VictoriaMetrics Operator


## üí¨ Envoyer des alertes sur slack


### Create a Slack app

https://api.slack.com/apps

* Add a new application "Alertmanager"
* Go to "Oauth & Permissions",
    * under "Scopes" add
    * `chat:write`
    * `chat:write.public` (Optional)
    * `channels:read` (Optional)
    * `groups:read` (Optional)

<center><video controls width="800" autoplay loop muted>
    <source src="slack-permissions.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video></center>

    * Generate a token under "OAuth tokens" and install it to your workspace
* Choose an Icon under "General"
* Test it with
```bash
curl -X POST -H 'Authorization: Bearer xoxb-...' \
-H 'Content-type: application/json' \
--data '{"channel":"#alerts","text":"This is a test message from my Slack app!"}' \
https://slack.com/api/chat.postMessage
```

You should get a message like

```json
{
  "ok": true,
  "channel": "C07HXJ4G59D",
  "ts": "1724571622.070789",
...
}
```

#### Configure Alertmanager

```yaml
    alertmanager:
      enabled: true

      spec:
        secrets:
          - "victoria-metrics-k8s-stack-alertmanager-slack-app"

      config:
        global:
          slack_api_url: "https://slack.com/api/chat.postMessage"
          http_config:
            authorization:
              credentials_file: /etc/vm/secrets/victoria-metrics-k8s-stack-alertmanager-slack-app/token

```



<center><img src="grafana-alerts.png" width=1100 alt=""></center>



```yaml
apiVersion: operator.victoriametrics.com/v1beta1
kind: VMServiceScrape
metadata:
  labels:
    app.kubernetes.io/name: hubble
  name: hubble
  namespace: kube-system
spec:
  endpoints:
    - honorLabels: true
      interval: 10s
      path: /metrics
      port: hubble-metrics
      relabelConfigs:
        - action: replace
          sourceLabels:
            - __meta_kubernetes_pod_node_name
          targetLabel: node
      scheme: http
  namespaceSelector:
    matchNames:
      - kube-system
  selector:
    matchLabels:
      k8s-app: hubble
```


```yaml
apiVersion: operator.victoriametrics.com/v1beta1
kind: VMRule
metadata:
  labels:
    prometheus-instance: main
  name: flux-system
  namespace: flux-system
spec:
  groups:
    - name: flux-system
      rules:
        - alert: FluxReconciliationFailure
          annotations:
            message: Flux resource has been unhealthy for more than 5m
            description: "{{ $labels.kind }} {{ $labels.exported_namespace }}/{{ $labels.name }} reconciliation has been failing for more than ten minutes."
            runbook_url: "https://fluxcd.io/flux/cheatsheets/troubleshooting/"
            dashboard: "https://grafana.priv.${domain_name}/dashboards"
          expr: max(gotk_reconcile_condition{status="False",type="Ready"}) by (exported_namespace, name, kind) + on(exported_namespace, name, kind) (max(gotk_reconcile_condition{status="Deleted"}) by (exported_namespace, name, kind)) * 2 == 1
          for: 10m
          labels:
            severity: warning
```


https://web.dev/articles/vitals
